{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class prepare_data:\n",
    "    def __init__(self, path_json_file, ratio=[0.8, 0.1, 0.1]):\n",
    "        self.data = pd.read_json(path_or_buf=path_json_file)[[\"band_1\", \"band_2\", \"inc_angle\", \"is_iceberg\"]]\n",
    "        self.ratio = ratio\n",
    "        self.whole_dataset = np.array([])  \n",
    "        print(\"All data size:\", self.data.shape)\n",
    "        \n",
    "        \n",
    "    def exclude_missing_inc_angle(self):\n",
    "        \"\"\"\n",
    "        Column `inc_angle` has value `na` in some rows (around 12% of data) and those rows are excluded\n",
    "        \"\"\"\n",
    "        self.data = self.data[self.data.inc_angle != \"na\"]\n",
    "    \n",
    "    \n",
    "    def normalize_inc_angle(self):\n",
    "        \"\"\"\n",
    "        Normalize column `inc_angle` in [−1,1]\n",
    "        \"\"\"\n",
    "        self.data[\"inc_angle\"] = (2*((self.data[\"inc_angle\"] - min(self.data[\"inc_angle\"]))/ (max(self.data[\"inc_angle\"] - min(self.data[\"inc_angle\"]))))-1)\n",
    "        \n",
    "        \n",
    "    def shuffle_data(self):\n",
    "        \"\"\"\n",
    "        Random shuffle data\n",
    "        \"\"\"\n",
    "        self.data = self.data.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    def array_to_matrix(self, a):\n",
    "        \"\"\"\n",
    "        Convert array with actual values - `y` - to a binary matrix\n",
    "        \"\"\"\n",
    "        mtrx = np.zeros((len(a),2))\n",
    "        for x in range(0,2):\n",
    "            indices = np.where(np.array(a).reshape(-1,1)[:,0]==x)\n",
    "            mtrx[indices, x] = 1\n",
    "        return(mtrx)\n",
    "    \n",
    "    \n",
    "    def reduce_spatial_dimension(self, image):\n",
    "        \"\"\"\n",
    "        Reduces dimension of a 75x75 image to 25x25\n",
    "        According to numpy.nbytes, the size of image before reduction is 45kB and 5kB after\n",
    "        Inputs:\n",
    "        - image: 2d array\n",
    "        Returns:\n",
    "        - reduced_image: Reduced image\n",
    "        \"\"\"\n",
    "        image = image.reshape(75, 75)\n",
    "        #print(image.shape)\n",
    "        reduced_image = np.zeros((25, 25))\n",
    "        filter_size = reduced_image.shape[0]\n",
    "        padding = int(image.shape[0] / reduced_image.shape[0])\n",
    "        counter = 0\n",
    "        counter_i = 0 # counter in i loop for indexing rows\n",
    "        for i in range(0, image.shape[0], padding):\n",
    "            counter_j = 0 # counter in j loop for indexing columns\n",
    "            for j in range(0, image.shape[1], padding):\n",
    "                max_val = np.max(image[i:padding+i, j:padding+j])\n",
    "                counter += 1\n",
    "                reduced_image[counter_i][counter_j] = max_val\n",
    "                counter_j += 1\n",
    "            counter_i += 1\n",
    "        return reduced_image.flatten()\n",
    "    \n",
    "    \n",
    "    def prepare_columns(self):\n",
    "        \"\"\"\n",
    "        Function converts Pandas columns to Numpy array, normalizes columns band_1 and band_2\n",
    "        and creates a new column with average values of band_1 and band_2\n",
    "        \"\"\"\n",
    "        self.shuffle_data()\n",
    "        \n",
    "        x_band_1 = np.array(self.data[\"band_1\"].tolist())\n",
    "        x_band_2 = np.array(self.data[\"band_2\"].tolist())\n",
    "        x_inc_angle = np.array(self.data[\"inc_angle\"].tolist()).reshape(-1,1)\n",
    "        y_is_iceberg = self.array_to_matrix(np.array(self.data[\"is_iceberg\"].tolist()).reshape(-1,1))\n",
    "        \n",
    "        # Normalize arrays `band_1` and `band_2` in  [−1,1], create array with average band values\n",
    "        x_band_1_norm = 2*((x_band_1 - np.min(x_band_1)) / (np.max(x_band_1) - np.min(x_band_1)))-1\n",
    "        x_band_2_norm = 2*((x_band_2 - np.min(x_band_2)) / (np.max(x_band_2) - np.min(x_band_2)))-1\n",
    "        temp_band_avg = np.add(x_band_1_norm, x_band_2_norm)/2\n",
    "        x_band_avg = np.apply_along_axis(self.reduce_spatial_dimension, 1, temp_band_avg)\n",
    "        print(\"x_band_avg.shape:\", x_band_avg.shape)\n",
    "        # Create the `whole_dataset_avg` matrix by stacking `x_inc_angle`, `x_band_avg` and `y_is_iceberg` arrays\n",
    "        # and do sanity check (print the shape of matrix)\n",
    "        self.whole_dataset = np.hstack((x_inc_angle, x_band_avg, y_is_iceberg))\n",
    "        print(\"Size of the whole dataset for training::\", self.whole_dataset.shape)\n",
    "                \n",
    "            \n",
    "    def prepare_sets(self):\n",
    "        \"\"\"\n",
    "        Prepare train, validate and test sets\n",
    "        \"\"\"\n",
    "        max_num_train = int(len(self.whole_dataset)*self.ratio[0])\n",
    "        max_num_validate = int(len(self.whole_dataset)*self.ratio[1])\n",
    "        max_num_test = int(len(self.whole_dataset)*self.ratio[2])\n",
    "        print(\"Split:\", max_num_train, max_num_validate, max_num_test)\n",
    "\n",
    "        X_train = self.whole_dataset[:max_num_train, :-2]\n",
    "        y_train = self.whole_dataset[:max_num_train, -2:]\n",
    "        X_validate = self.whole_dataset[max_num_train : max_num_train+max_num_validate, :-2]\n",
    "        y_validate = self.whole_dataset[max_num_train : max_num_train+max_num_validate, -2:]\n",
    "        X_test = self.whole_dataset[max_num_train+max_num_validate:, :-2]\n",
    "        y_test = self.whole_dataset[max_num_train+max_num_validate:, -2:]\n",
    "        \n",
    "        print(\"X_train:\", X_train.shape)\n",
    "        print(\"y_train:\", y_train.shape)\n",
    "        print(\"X_validate:\", X_validate.shape)\n",
    "        print(\"y_validate:\", y_validate.shape)\n",
    "        print(\"X_test:\", X_test.shape)\n",
    "        print(\"y_test:\", y_test.shape)\n",
    "\n",
    "        return X_train, y_train, X_validate, y_validate, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mlp:\n",
    "    def __init__(self, n_neurons_input, n_neurons_hidden, n_targets, learning_rate=0.5, beta=1):\n",
    "        np.set_printoptions(suppress=True) #suppress scientific notation\n",
    "        self.n_neurons_input = n_neurons_input\n",
    "        self.n_targets = n_targets # number of target neurons\n",
    "        self.n_neurons_hidden = n_neurons_hidden # number of neurons in hidden layer\n",
    "\n",
    "        #intervals for picking random weights for hidden layer\n",
    "        low_hidden = -1/math.sqrt(self.n_neurons_input)\n",
    "        high_hidden = 1/math.sqrt(self.n_neurons_input)\n",
    "        self.weights_hidden = np.random.uniform(low_hidden, high_hidden, size=(self.n_neurons_input, self.n_neurons_hidden))\n",
    "\n",
    "        #intervals for picking random weights for output layer\n",
    "        low_output = -1/math.sqrt(self.n_neurons_hidden)\n",
    "        high_output = 1/math.sqrt(self.n_neurons_hidden)\n",
    "        self.weights_output =  np.random.uniform(low_output, high_output, size=(self.n_targets, self.n_neurons_hidden))\n",
    "\n",
    "        self.bias_hidden_weight = np.array([np.random.rand()] * self.n_neurons_hidden)\n",
    "        self.bias_output_weight = np.array([np.random.rand()] * self.n_targets)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.beta = beta #hyperparameter used in sigmoid function\n",
    "\n",
    "        #prepare the arrays\n",
    "        self.hidden_layer_activation = np.array([0.] * self.n_neurons_hidden)\n",
    "        self.hidden_layer_activation_f_output = np.array([0.] * self.n_neurons_hidden)\n",
    "        self.hidden_layer_error = np.array([0.] * self.n_neurons_hidden)\n",
    "        self.output_layer_output = np.array([0.] * self.n_targets)\n",
    "        self.output_layer_activation = np.array([0.] * self.n_targets)\n",
    "        self.output_layer_error = np.array([0.] * self.n_targets)\n",
    "\n",
    "        self.all_total_errors = np.array([])\n",
    "        \n",
    "        self.validation_error = []\n",
    "        \n",
    "    def sigmoid(self, x, beta):\n",
    "        \"\"\"\n",
    "        Activation function (sigmoid function, continuous-log sigmond function)\n",
    "        Sigmoid is acceptable when having a classification problem\n",
    "        Inputs:\n",
    "        - x: float\n",
    "        - beta: slope parameter\n",
    "        Returns float\n",
    "        \"\"\"\n",
    "        return 1 / (1 + math.exp(-x * beta))\n",
    "    \n",
    "    def derivative_sigmoid(self, a):\n",
    "        \"\"\"\n",
    "        Calculates the derivative of sigmoid function - x*(1-x)\n",
    "        Inputs:\n",
    "        - a: array of floats\n",
    "        Returns derivative of the array\n",
    "        \"\"\"\n",
    "        return (a*(1-a))\n",
    "\n",
    "    def forward_hidden_layer(self, inputs):\n",
    "        \"\"\"\n",
    "        Calculates hidden layer activations and outputs from activation function\n",
    "        Inputs: \n",
    "        - inputs: array (row) of training data\n",
    "        Returns:\n",
    "        - hla: hidden layer activation\n",
    "        - hlafo: hidden layer with applied activation function\n",
    "        \"\"\"\n",
    "        hla = np.transpose(np.dot(np.transpose(inputs), self.weights_hidden))\n",
    "        hlafo = np.array([self.sigmoid(x, self.beta) for x in np.transpose(hla)])\n",
    "        return hla, hlafo\n",
    "\n",
    "    def forward_output_layer(self, sigmoid_from_hidden_layer):\n",
    "        \"\"\"\n",
    "        Calculate output layer based on values from the hidden layer\n",
    "        Inputs:\n",
    "        - sigmoid_from_hidden_layer: array with values after activation function has been applied\n",
    "                                     length = number of neurons in the hidden layer\n",
    "        Returns:\n",
    "        - olo: array for output from output layer\n",
    "        - ola: array for output from output layer activation\n",
    "        \"\"\"\n",
    "        n_rows = sigmoid_from_hidden_layer.shape[0]\n",
    "        olo = np.dot(sigmoid_from_hidden_layer.reshape(1,n_rows), np.transpose(self.weights_output)) + self.bias_output_weight\n",
    "        ola = np.array([self.sigmoid(x, self.beta) for x in np.transpose(olo)])\n",
    "        return olo, ola\n",
    "\n",
    "    def calculate_total_error(self, t, o):\n",
    "        \"\"\"\n",
    "        Calculate error between actual targets (t) and output targets (o)\n",
    "        Inputs:\n",
    "        - t: actual target (y) values. Array either [1, 0] or [0, 1] \n",
    "        - o: calculated values. Array of floats with length 2\n",
    "        Returns:\n",
    "        - total_error: float \n",
    "        \"\"\"\n",
    "        total_error = np.sum(1/2 * (t - o) ** 2)\n",
    "        return total_error\n",
    "\n",
    "   ################################# \n",
    "   # Functions for backpropagation #\n",
    "   #################################\n",
    "    \n",
    "    ##for every output neuron\n",
    "    def calculate_output_error(self):\n",
    "        \"\"\"\n",
    "        Calculates output error before going into backpropagation\n",
    "        \"\"\"\n",
    "        self.output_layer_error = (self.output_layer_activation - self.targets) * self.output_layer_activation * (1 - self.output_layer_activation)\n",
    "\n",
    "    \n",
    "    def backward_hidden_error(self):\n",
    "        \"\"\"\n",
    "        Calculate the error in the hidden layer\n",
    "        \"\"\"\n",
    "        #first part of the equation - the derivative of the activation function - (x*(1-x))\n",
    "        derivative_part = self.derivative_sigmoid(self.hidden_layer_activation_f_output) #self.hidden_layer_activation_f_output * (1 - self.hidden_layer_activation_f_output)\n",
    "        # second part of the equation - sum of product of weights in hidden layer and the error of the output\n",
    "        n_rows_ole = self.output_layer_error.shape[0]\n",
    "        n_rows_hla = self.hidden_layer_activation.shape[0]\n",
    "        #a matrix is returned and the diagonal has the values we are after\n",
    "        self.hidden_layer_error2 =  np.diagonal(np.transpose(derivative_part) * self.hidden_layer_activation.reshape(n_rows_hla,1) * np.transpose(self.output_layer_error.reshape(n_rows_ole,1)[0]))\n",
    "\n",
    "    def update_output_layer_weights(self):\n",
    "        \"\"\"\n",
    "        Updates weights in the output layer\n",
    "        \"\"\"\n",
    "        n_rows = self.hidden_layer_activation_f_output.shape[0]\n",
    "        self.weights_output = self.weights_output - np.transpose(self.learning_rate * self.output_layer_error * np.transpose(self.hidden_layer_activation_f_output.reshape(1,n_rows)))\n",
    "        self.bias_output_weight = self.bias_output_weight - (self.learning_rate * self.output_layer_error * 1)\n",
    "\n",
    "    def update_hidden_layer_weights(self):\n",
    "        \"\"\"\n",
    "        Updates weights in the hidden layer\n",
    "        \"\"\"\n",
    "        n_rows = self.inputs.shape[0]\n",
    "        self.weights_hidden = self.weights_hidden - (self.learning_rate * self.hidden_layer_error * np.transpose(self.inputs.reshape(1, n_rows)))\n",
    "        self.bias_hidden_weight = self.bias_hidden_weight - (self.learning_rate * self.hidden_layer_activation * 1)\n",
    "\n",
    "    ##################\n",
    "    ##train network  #\n",
    "    ################\n",
    "    def train(self, inputs, targets):\n",
    "        \"\"\"\n",
    "        Calls all methods for forward and back pass through the network\n",
    "        Inputs:\n",
    "        - inputs: array of floats - one test sample\n",
    "        - targets: array of targets - correct output value\n",
    "        \"\"\"\n",
    "        self.inputs = inputs\n",
    "        self.n_inputs = self.inputs.shape[0]\n",
    "        self.targets = targets\n",
    "\n",
    "        ## Forward pass #\n",
    "        self.hidden_layer_activation, self.hidden_layer_activation_f_output = self.forward_hidden_layer(self.inputs)\n",
    "        self.output_layer_output, self.output_layer_activation = self.forward_output_layer(self.hidden_layer_activation_f_output)\n",
    "        self.calculate_total_error(self.targets, self.output_layer_activation)\n",
    "\n",
    "        ## Backward pass #\n",
    "        self.calculate_output_error()\n",
    "        self.backward_hidden_error()\n",
    "        self.update_output_layer_weights()\n",
    "        self.update_hidden_layer_weights()\n",
    "    #end train\n",
    "\n",
    "    def train_network(self, train, target, n_epoch=10):\n",
    "        self.n_epoch = n_epoch\n",
    "        n_rows = train.shape[0]\n",
    "        for epoch in range(self.n_epoch):\n",
    "            for i in range(0, n_rows):\n",
    "                self.train(train[i], target[i])\n",
    "            print(\"epoch number:\", epoch, \", error=\",  self.calculate_total_error(self.targets, self.output_layer_activation))\n",
    "\n",
    "    def early_stopping(self, train, target, valid, valid_target, n_epoch=10):\n",
    "        self.n_epoch = n_epoch\n",
    "        n_rows = train.shape[0]\n",
    "        previous_valid_error = 100\n",
    "        message = \"\"\n",
    "        for epoch in range(self.n_epoch):\n",
    "            for i in range(0, n_rows):\n",
    "                #print(\"row\", i)\n",
    "                self.train(train[i], target[i])\n",
    "            #print(\"early stopping: self.output_layer_activation\", self.output_layer_activation.shape, target.shape)\n",
    "            #print(\"number of training rows processed:\", n_rows)\n",
    "            #print(\"VALIDATE!\")\n",
    "            test_error = self.calculate_total_error(self.targets, self.output_layer_activation)\n",
    "            valid_error = self.forward_pass_with_calculated_error(valid, valid_target)\n",
    "            self.validation_error.append(valid_error) # list for visualizing validation error\n",
    "            \n",
    "            #early break is in effect after 10% of the epochs is run\n",
    "            if (epoch > self.n_epoch/10) and (valid_error > previous_valid_error):\n",
    "            #if (valid_error > previous_valid_error):\n",
    "                message = \"STOP\"\n",
    "            previous_valid_error = valid_error\n",
    "            #print(\"epoch number:\", epoch, \", error=\", test_error, \", valid error=\", valid_error)\n",
    "\n",
    "            #print(epoch, \"\\t\", test_error, \"\\t\",valid_error, \"\\t\", message)\n",
    "            clear_output(wait=True)\n",
    "            #display('Iteration '+str(i)+' Score: '+str(uniform(0, 1)))\n",
    "            #print(\"epoch: %s test_error: %s\\tvalidation_error: %s %s\" % (epoch, test_error, valid_error, message))\n",
    "            display(\"epoch: %s test_error: %s validation_error: %s %s\" % (epoch+1, test_error, valid_error, message))\n",
    "            if message == \"STOP\":\n",
    "                break\n",
    "        \n",
    "        self.plot_validation_error(self.validation_error)\n",
    "\n",
    "    def forward_pass_with_calculated_error(self, input_set, target_set):\n",
    "        #local arrays for activation and sigmoid values\n",
    "        #hidden_layer_activation = np.array([0.] * self.n_neurons_hidden)\n",
    "        #hidden_layer_activation_f_output = np.array([0.] * self.n_neurons_hidden)\n",
    "\n",
    "        output_layer_output = np.array([0.] * self.n_targets)\n",
    "        output_layer_activation = np.array([0.] * self.n_targets)\n",
    "\n",
    "        total_error = 0\n",
    "        n_rows = input_set.shape[0]\n",
    "        for i in range(n_rows):\n",
    "            hidden_layer_activation, hidden_layer_activation_f_output = self.forward_hidden_layer(input_set[i])\n",
    "            output_layer_output, output_layer_activation = self.forward_output_layer(hidden_layer_activation_f_output)\n",
    "\n",
    "            error = self.calculate_total_error(target_set[i], output_layer_activation)\n",
    "            total_error = total_error + error\n",
    "\n",
    "        total_error = total_error/n_rows\n",
    "        return total_error\n",
    "        \n",
    "    def array_values_to_binary(self, a):\n",
    "        \"\"\"\n",
    "        Look for max float in array, assign 1 to the index and 0 to other index (array has length 2).\n",
    "        Inputs:\n",
    "        - a: array of float\n",
    "        Returns a binary array with one 0 and one 1\n",
    "        \"\"\"\n",
    "        index = np.argmax(a)\n",
    "        result = np.zeros_like(a)\n",
    "        result[index] = 1\n",
    "        return result\n",
    "\n",
    "    #method delivers final statistics on the model accuracy\n",
    "    def confusion(self, inputs, targets, threshold_value=0.5):\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        n_rows, n_classes = targets.shape\n",
    "        percentage = 0\n",
    "\n",
    "        mtrx = np.zeros((n_classes, n_classes)) #initialize matrix\n",
    "\n",
    "        for i in range(n_rows):\n",
    "            hidden_layer_activation, hidden_layer_activation_f_output = self.forward_hidden_layer(inputs[i])\n",
    "            output_layer_output, output_layer_activation = self.forward_output_layer(hidden_layer_activation_f_output)\n",
    "            #print(\"\\nrow:\", i)\n",
    "            #print(\"output_layer_activation:\", output_layer_activation)\n",
    "            binary_output = self.array_values_to_binary(output_layer_activation)\n",
    "            #print(\"output:\", binary_output, \"target:\", targets[i])\n",
    "            #print(\"t:\", targets[i])\n",
    "\n",
    "            o_one_position = np.where(binary_output == 1)[0] #find position of 1 in array\n",
    "            t_one_position = np.where(targets[i] == 1)[0] #find position of 1 in array\n",
    "            \n",
    "            if o_one_position == t_one_position:\n",
    "                percentage = percentage + 1\n",
    "\n",
    "            #write matrix\n",
    "            mtrx[o_one_position, t_one_position] = mtrx[o_one_position, t_one_position] + 1\n",
    "\n",
    "        print(\"Match coefficient:\", round(percentage/n_rows, 4))\n",
    "        print(mtrx)\n",
    "\n",
    "    def plot_validation_error(self, validation_error):\n",
    "        plt.plot(validation_error)\n",
    "        plt.show()\n",
    "        \n",
    "##end class neural_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data size: (1604, 4)\n"
     ]
    }
   ],
   "source": [
    "file_path = \"../data/processed/train.json\"\n",
    "prep = prepare_data(path_json_file=file_path, ratio=[0.9, 0.05, 0.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_band_avg.shape: (1471, 625)\n",
      "Size of the whole dataset for training:: (1471, 628)\n",
      "Split: 1323 73 73\n",
      "X_train: (1323, 626)\n",
      "y_train: (1323, 2)\n",
      "X_validate: (73, 626)\n",
      "y_validate: (73, 2)\n",
      "X_test: (75, 626)\n",
      "y_test: (75, 2)\n"
     ]
    }
   ],
   "source": [
    "prep.exclude_missing_inc_angle()\n",
    "prep.normalize_inc_angle()\n",
    "prep.prepare_columns()\n",
    "\n",
    "X_train_avg, y_train_avg, X_validate_avg, y_validate_avg, X_test_avg, y_test_avg = prep.prepare_sets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_epochs = 300\n",
    "number_of_neurons_in_hidden = 32\n",
    "beta = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'epoch: 220 test_error: 0.7619170121653933 validation_error: 0.25769130024617315 STOP'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seconds used for training: 72.0040\n",
      "Match coefficient: 0.7333\n",
      "[[25.  8.]\n",
      " [12. 30.]]\n"
     ]
    }
   ],
   "source": [
    "X = X_train_avg\n",
    "target = y_train_avg\n",
    "X_validate = X_validate_avg\n",
    "y_validate = y_validate_avg\n",
    "X_test = X_test_avg\n",
    "y_test = y_test_avg\n",
    "\n",
    "number_of_neurons_in_input = X.shape[1]\n",
    "number_of_targets = target.shape[1]\n",
    "\n",
    "net = mlp(number_of_neurons_in_input, number_of_neurons_in_hidden, number_of_targets, beta=beta)\n",
    "\n",
    "t0 = time.time()\n",
    "net.early_stopping(X, target, X_validate, y_validate, number_of_epochs)\n",
    "t1 = time.time()\n",
    "total_time = t1-t0\n",
    "print(\"Seconds used for training: %0.4f\" % total_time)\n",
    "\n",
    "net.confusion(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
